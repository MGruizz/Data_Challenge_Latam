{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Challenge - Miguel Guerrero\n",
    "\n",
    "obs: Se importan las librerias dentro del segmento de codigo de cada solucion con el objetivo que sea utilizado unicamente ahi a pesar que puede ser reutilizado en otro segmento\n",
    "esto con el objetivo de aportar claridad a las librerias necesarias para el funcionamiento de la solucion\n",
    "\n",
    "- El archivo json se tiene en el directorio raiz de este archivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Las top 10 fechas donde hay más tweets. \n",
    "Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días.\n",
    "- Enfoque: Tiempo de ejecucion optimizado\n",
    "\n",
    "Para este caso se convierte el archivo json a un dataframe de pandas por los beneficios que este tiene en la optimizacion de las operaciones con datos.\n",
    "Como se esta priorizando el tiempo de ejecucion por sobre de la memoria. Ademas luego de leer el JSON, se guarda el DF en formato Parquet para uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "\n",
    "#Se define la funcion que nos devolvera la top 10 fechas con mas tweets y se menciona el usuario con mas tweets en estas fechas con enfoque en optimizacion del tiempo de ejecucion\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \n",
    "    #Se ajusta ruta de lectura de archivo json a .parquet para futuras lecturas\n",
    "    parquet_file = file_path.replace('.json', '.parquet')\n",
    "    \n",
    "    #Se verifica si el archivo .parquet existe, si existe se lee, si no se crea\n",
    "    if os.path.exists(parquet_file):\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "    else:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        df.to_parquet(parquet_file, index=False)\n",
    "    \n",
    "\n",
    "    #Se convierte la columna date a datetime de pandas y extraemos solo la fecha\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "    \n",
    "    #Se extrae el nombre de usuario de la columna user\n",
    "    df['username'] = df['user'].apply(lambda x: x.get('username'))\n",
    "    \n",
    "    #Se elimina la columna user\n",
    "    del df['user']\n",
    "\n",
    "    #Se agrupa el DataFrame por fecha y nombre de usuario y se cuenta el número de tweets para cada combinación\n",
    "    grouped = df.groupby(['date', 'username']).size().reset_index(name='count')\n",
    "\n",
    "    #Se obtiene las 10 fechas con el mayor número de tweets.\n",
    "    top_dates_df = df['date'].value_counts().nlargest(10).reset_index()\n",
    "\n",
    "    # Se obtiene el usuario con mas tweets para cada una de las 10 fechas\n",
    "    result = []\n",
    "    for _, row in top_dates_df.iterrows():\n",
    "        date = row['date']\n",
    "        top_user_df = grouped[grouped['date'] == date].nlargest(1, 'count')\n",
    "        top_user = top_user_df['username'].iloc[0]\n",
    "        result.append((date, top_user))\n",
    "    \n",
    "    return result\n",
    "\n",
    "#Se ejecuta la funcion\n",
    "#q1_time('./farmers-protest-tweets-2021-2-4.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque: Memoria en uso optimizada\n",
    "\n",
    "Para este se utiliza el archivo json y se lee linea por linea.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "import ujson as json\n",
    "\n",
    "#Se define la funcion que nos devolvera la top 10 fechas con mas tweets y se menciona el usuario con mas tweets en estas fechas con enfoque en optimizacion de la memoria en uso\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \n",
    "    # Diccionario para mantener el conteo de tweets por fecha\n",
    "    date_counts = defaultdict(int)\n",
    "    # Diccionario para mantener el conteo de tweets de usuario por fecha\n",
    "    user_date_counts = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            # Se extrae la date del tweet y la convertimos a datetime.date\n",
    "            tweet_date = datetime.strptime(tweet['date'].split(\"T\")[0], '%Y-%m-%d').date()\n",
    "            # Se actualiza el conteo de tweets para esa fecha\n",
    "            date_counts[tweet_date] += 1\n",
    "            # Se actualiza el conteo de tweets de usuario para esa fecha\n",
    "            user_date_counts[tweet_date][tweet['user']['username']] += 1\n",
    "\n",
    "    # Se ordena las fechas por numero de tweets de forma descendente y se guarda el top 10\n",
    "    top_dates = sorted(date_counts, key=date_counts.get, reverse=True)[:10]\n",
    "    # Para cada fecha, se obtiene el usuario con mas tweets\n",
    "    result = []\n",
    "    for date in top_dates:\n",
    "        #Se obtiene el usuario con mas tweets para cada fecha\n",
    "        top_user = max(user_date_counts[date], key=user_date_counts[date].get)\n",
    "        result.append((date, top_user))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Se ejecuta la funcion\n",
    "#q1_memory('./farmers-protest-tweets-2021-2-4.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Los top 10 emojis más usados con su respectivo conteo.\n",
    "Enfoque: Tiempo de ejecucion optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import emoji\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Se define la funcion que nos devolvera la lista de los 10 emojis mas usados con enfoque en optimizacion del tiempo de ejecucion\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \n",
    "    # Se ajusta ruta de lectura de archivo json a .parquet para futuras lecturas\n",
    "    parquet_file = file_path.replace('.json', '.parquet')\n",
    "    \n",
    "    # Se verifica si el archivo .parquet existe, si existe se lee, si no se crea\n",
    "    if os.path.exists(parquet_file):\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "    else:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        df.to_parquet(parquet_file, index=False)\n",
    "    \n",
    "    # Se extraen todos los emojis de la columna 'content' y se cuenta su frecuencia\n",
    "    all_emojis = []\n",
    "    for content in df['content']:\n",
    "        emojis_in_content = [entry['emoji'] for entry in emoji.emoji_list(content)]\n",
    "        all_emojis.extend(emojis_in_content)\n",
    "    # Se cuenta la frecuencia de cada emoji\n",
    "    emoji_counts = Counter(all_emojis)\n",
    "\n",
    "    # Se obteniene los top 10 emojis más utilizados\n",
    "    top_emojis = emoji_counts.most_common(10)\n",
    "    \n",
    "    return top_emojis\n",
    "\n",
    "#Se ejecuta la funcion\n",
    "#q2_time('./farmers-protest-tweets-2021-2-4.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque: Memoria en uso optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "import emoji\n",
    "\n",
    "#Se define la funcion que nos devolvera la lista de los 10 emojis mas usados con enfoque en optimizacion de la memoria en uso\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \n",
    "    # Se crea un counter para contar la frecuencia de cada emoji\n",
    "    emoji_counts = Counter()\n",
    "    \n",
    "    # Se abre el archivo json y se itera sobre cada tweet\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Se convierte la linea en un diccionario\n",
    "            tweet = json.loads(line)\n",
    "            # Se extrae el contenido del tweet\n",
    "            content = tweet.get('content', '')\n",
    "            # Se extraen los emojis del contenido\n",
    "            emojis_in_content = [entry['emoji'] for entry in emoji.emoji_list(content)]\n",
    "                \n",
    "            # Se actualiza el counter con los emojis encontrados\n",
    "            emoji_counts.update(emojis_in_content)\n",
    "\n",
    "    # Se obtienen los top 10 emojis más utilizados\n",
    "    top_emojis = emoji_counts.most_common(10)\n",
    "    \n",
    "    return top_emojis\n",
    "\n",
    "#Se ejecuta la funcion\n",
    "#q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos. \n",
    "Enfoque: Tiempo de ejecucion optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "#Se define la funcion que nos devolvera la lista de los 10 usuarios mas mencionados en tweets con enfoque en la optimizacion del tiempo de ejecucion\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \n",
    "    #Se ajusta ruta de lectura de archivo json a .parquet para futuras lecturas\n",
    "    parquet_file = file_path.replace('.json', '.parquet')\n",
    "    \n",
    "    #Se verifica si el archivo .parquet existe, si existe se lee, si no se crea\n",
    "    if os.path.exists(parquet_file):\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "    else:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        df.to_parquet(parquet_file, index=False)\n",
    "    \n",
    "    \n",
    "    #Se extraen todas las menciones por cada tweet\n",
    "    df['mentions'] = df['content'].str.findall(r'@(\\w+)')\n",
    "\n",
    "    # Se aplana la lista de menciones, ya que cada tweet puede tener más de una mención\n",
    "    mentions_flat = []\n",
    "    for sublist in df['mentions'].dropna():\n",
    "        for mention in sublist:\n",
    "            mentions_flat.append(mention)\n",
    "    # Se cuenta la frecuencia de cada mención en la lista aplanada\n",
    "    mention_counts = Counter(mentions_flat)\n",
    "    # Obtener los top 10 usuarios más mencionados\n",
    "    top_mentions = mention_counts.most_common(10)\n",
    "    \n",
    "    return top_mentions\n",
    "\n",
    "#Se ejecuta la funcion\n",
    "#q3_time('./farmers-protest-tweets-2021-2-4.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfoque: Memoria en uso optimizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import re\n",
    "\n",
    "#Se define la funcion que nos devolvera la lista de los 10 usuarios mas mencionados en tweets con enfoque en la optimizacion de la memoria en uso\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \n",
    "    # Se crea un counter para contar la frecuencia de cada mención\n",
    "    mention_counts = Counter()\n",
    "    \n",
    "    # Se abre el archivo json y se itera sobre cada tweet\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            content = tweet.get('content', '')\n",
    "            # Se extraen las menciones del contenido\n",
    "            mentions = re.findall(r'@(\\w+)', content)\n",
    "            # Se actualiza el counter con las menciones encontradas\n",
    "            mention_counts.update(mentions)\n",
    "            \n",
    "    # Obtener los top 10 usuarios más mencionados\n",
    "    top_mentions = mention_counts.most_common(10)\n",
    "    \n",
    "    return top_mentions\n",
    "\n",
    "#Se ejecuta la funcion\n",
    "#q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posibles mejoras generales orientadas al enfoque de tiempo de ejecucion optimo:\n",
    "\n",
    "- Tener el archivo .parquet preparado con las columnas necesarias y de este modo restarle carga a la funcion y solo se enfoque a operar sobre el dataframe. Incluso de ser posible tener listo el archivo solo con las columnas necesarias.\n",
    "\n",
    "Comentario: La solucion con archivo parquet en algunos casos en la primera ejecucion no es la mas rapida pero en futuras ejecuciones es la que hace un mejor uso del tiempo de ejecucion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from memory_profiler import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmento para evaluar Q1\n",
    "\n",
    "# Evaluacion de uso de memoria: \n",
    "\n",
    "%load_ext memory_profiler\n",
    "%memit q1_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "%memit q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Evaluacion de tiempo de ejecucion: \n",
    "# Codigo a evaluar:\n",
    "q1_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q1_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats\")\n",
    "stats = pstats.Stats(\"output.pstats\")\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmento para evaluar Q2\n",
    "\n",
    "# Evaluacion de uso de memoria: \n",
    "\n",
    "%load_ext memory_profiler\n",
    "%memit q2_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "%memit q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Evaluacion de tiempo de ejecucion: \n",
    "# Codigo a evaluar:\n",
    "q2_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q2_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats\")\n",
    "stats = pstats.Stats(\"output.pstats\")\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmento para evaluar Q3\n",
    "\n",
    "# Evaluacion de uso de memoria: \n",
    "\n",
    "%load_ext memory_profiler\n",
    "%memit q3_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "%memit q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "# Evaluacion de tiempo de ejecucion: \n",
    "# Codigo a evaluar:\n",
    "q3_memory(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "q3_time(\"./farmers-protest-tweets-2021-2-4.json\")\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats\")\n",
    "stats = pstats.Stats(\"output.pstats\")\n",
    "stats.sort_stats(\"cumulative\")\n",
    "stats.print_stats(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
